
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Mahesh Arumugam is a software engineer passionate about designing, programming, and deploying systems. Currently, I work in data security and analytics domain.\n","date":1682899200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1682899200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Mahesh Arumugam is a software engineer passionate about designing, programming, and deploying systems. Currently, I work in data security and analytics domain.","tags":null,"title":"Mahesh Arumugam","type":"authors"},{"authors":null,"categories":null,"content":"Much like cursive writing in English, the Japanese language has Kuzushiji, roughly translating to squished writing. This writing style was used for over a thousand years beginning in the 8th century but is not taught in modern day curricula. As a result, most Japanese natives, aside from a select few experts, can read Kuzushiji. Most conversion of these works from Kuzushiji to modern Japanese is done by hand and takes countless hours for just a single document. However, with the relatively recent effort by museums and libraries to digitize ancient works in an effort to safeguard these priceless artifacts against natural disasters, the use of AI for these conversions has become suddenly more realistic. This project looks to build on existing work to restore deteriorated ancient texts through the use of generative AI such as GANs or the more advanced Diffusion Models. Converting these works into modern legible Japanese can help better understand, as well as preserve the history and culture of the Japanese people.\n","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701388800,"objectID":"47029d398a23f39fd071d6f16440628d","permalink":"/project/capstone-mids/","publishdate":"2023-12-01T00:00:00Z","relpermalink":"/project/capstone-mids/","section":"project","summary":"This project looks to build on existing work to restore deteriorated ancient texts through the use of optical character recognition and generative AI such as GANs or the more advanced Diffusion Models.","tags":["Machine Learning","Data Science","LLM","MIDS"],"title":"Restor-AI-tion: Ancient Handwritten Japanese Texts Restoration","type":"project"},{"authors":["Mahesh Arumugam","Catherine Jimerson","Diamond Rorie","Amangeet Samra","Amrita Mande","Daniel Aranki"],"categories":null,"content":"Verifying sources of information is vital in assessing the credibility of facts and data in our increasingly digital world; often, the verification of the sources is as necessary as the information they provide.To battle misinformation and disinformation through digital objects, it is salient to provide consumers the ability to verify whether or not information (or data) provided by such sources was altered prior to its use (e.g., publication). Furthermore, if such an object is altered, it would also be essential to provide a means to trace back such information throughout its editing lineage in a verifiable manner.This research aims to fill the gaps in verifiable proof of sources of information, software supply-chain, and objects in other similarly critical domains.\nWe propose Signet-ring, a framework that provides referenceable documentation of the relationship between a digital object and its sources. In addition, the framework documents the object’s lifetime as it goes through various edits (lineage), including those by others within the framework. As such, Signet-ring provides a verifiable means for anyone to authenticate the sources of any digital object registered to it and track the object’s progression in time. This framework can be used, for example, by journalists and publishers to verify the sources of their materials (e.g., videos or images) and provide this proof to their readers for their verification. This, in turn, introduces a new layer of trust to the public in the reporting they consume.\nAnother noteworthy use case for Signet-ring is aiding the assurance process in software supply chains. The various stages and components of software can be certified using Signet-ring to provide verifiable checkpoints of revisions that pass assurance guarantees. For example, consider a program or a change-list (e.g., a pull request) that one person authentically creates and registers within Signet-ring. Suppose this code becomes visible, and any third-party modifications (not authenticated by the framework) are available. Then, only the change within the framework will have a traceable relationship to the source and its lineage. Thus, the framework enables various stakeholders to verify the relationship between sources and software objects, including changes made to revisions of software with certified assurances.\nIn this presentation, we present the architecture of the Signet-ring. signet-ring registers and authenticates all participants in the origination and publication process, potentially including the sources, publishers, and applications. It manages the following critical workflows:\ndocumentation and verification of the relationships between objects and sources (certification), documentation and verification of the relationships between different related objects (lineage), and authentication of sources to each other (handshake). Furthermore, Signet-ring supports the lifecycle management of source identities (using cryptographic keys) and relationships between objects and sources. This lifecycle management includes the revocation of source identity keys and previously accepted object-source relationships.\n","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"2baa982e50828c5d500992b6d2879779","permalink":"/publication/signet-ring-hcss23/","publishdate":"2023-05-01T00:00:00Z","relpermalink":"/publication/signet-ring-hcss23/","section":"publication","summary":"A framework for authenticatin sources and lineages of digital objects.","tags":[],"title":"Signet-ring: A framework for authenticating sources and lineages of digital objects","type":"publication"},{"authors":null,"categories":null,"content":"In this project, we investigate the urban land use dataset from UC Merced that consists of 21 land use categories from various urban areas across the United States. We explore various features of the images, starting from simple ones such as mean color values of the color channels and histogram of oriented gradients, to complex features such as bag of visual words, contours of an image, and embeddings from pre-trained deep neural network models (e.g., VGG16 and ResNet101). We perform principal component analysis to reduce the dimensionality of our dataset for better generalizability. We identify features suitable for classifying the images into their respective classes through experiments with various classification models. Finally, we compare and contrast these classification models for efficiency (with respect to the time required for training and prediction) and model accuracy.\n","date":1680307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680307200,"objectID":"9efe6d5d4a700d2a861b91ec2c6cdc65","permalink":"/project/landuse-mids/","publishdate":"2023-04-01T00:00:00Z","relpermalink":"/project/landuse-mids/","section":"project","summary":"In this project, we investigate the urban land use dataset from UC Merced that consists of 21 land use categories from various urban areas across the United States.","tags":["Machine Learning","Data Science","MIDS"],"title":"Urban Land Use Classification from Public Domain Imagery","type":"project"},{"authors":null,"categories":null,"content":"Verifying sources of information is vital in assessing the credibility of facts and data in our increasingly digital world; often, the verification of the sources is as necessary as the information they provide. To battle misinformation and disinformation through digital objects, it is salient to provide consumers the ability to verify whether or not information (or data) provided by such sources was altered prior to its use (e.g., publication). To address these concerns, we designed and implemented Signet-ring. Signet-ring registers and authenticates all participants in the origination and publication process, potentially including the sources, publishers, and applications. It manages the following critical workflows: (1) documentation and verification of the relationships between objects and sources (certification), (2) documentation and verification of the relationships between different related objects (lineage), and (3) authentication of sources to each other (handshake). Furthermore, Signet-ring supports the lifecycle management of source identities (using cryptographic keys) and relationships between objects and sources. This lifecycle management includes the revocation of source identity keys and previously accepted object-source relationships.\n","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669852800,"objectID":"71e2e1602e970ae213a8ad26470edbd2","permalink":"/project/signet-ring/","publishdate":"2022-12-01T00:00:00Z","relpermalink":"/project/signet-ring/","section":"project","summary":"A framework for authenticatin sources and lineages of digital objects.","tags":["Data Science","Privacy","MIDS"],"title":"Signet-ring: A framework for authenticating sources and lineages of digital objects","type":"project"},{"authors":null,"categories":null,"content":"There has been considerable research in building pre-trained models for programming language tasks, such as CodeBERT and CodeT5, that enable several downstream tasks, including code summarization, generation, and translation. In this paper, we focus on the task of automated code summarization that translates Python source code into a natural language docstring. Towards this end, we propose CodeT5++, extensions to CodeT5 where we introduce novel pre-training tasks that capture relevant source code features most useful in code summarization tasks. Specifically, we pretrain the model to (1) predict masked return values of Python functions, (2) detect whether a docstring and source code pair is an accurate representation of the function, and (3) predict masked function names of Python functions.Subsequently, we fine-tune the models for the code summarization task and evaluate the performance using a smoothed BLEU-4 score, a precision-based metric applicable in translation tasks. Finally, we analyze how the pre-training steps help improve the summarization tasks.\n","date":1659312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659312000,"objectID":"785abdc7b0dab391a8d4fcffc5d668f3","permalink":"/project/codet5++-mids/","publishdate":"2022-08-01T00:00:00Z","relpermalink":"/project/codet5++-mids/","section":"project","summary":"In this paper, we focus on the task of automated code summarization that translates Python source code into a natural language docstring.","tags":["Machine Learning","Data Science","LLM","MIDS"],"title":"CodeT5++: A Pre-trained Programming Language Model for Code Summarization Task","type":"project"},{"authors":null,"categories":null,"content":"Air travel has a significant role in shaping economies of states and this it is important to optimize every aspect of the flight cycle to increase the quality of airline’s services, especially, the consistent on-time departure of flights. However, due to multiple factors, airline flight delay is inevitable, and thus have to be accounted for by the airline company executives in order to optimize value to multiple stakeholders –from the shareholders to the customers. In this project, we seek to address the following question: can weather and airline data collected two hours before the scheduled departure time, predict whether the flight will be delayed 15 minutes or more? The models we developed in this project, predict the delay with an accuracy of $82%$.\n","date":1648771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648771200,"objectID":"27499965dbaceaccd68f8936185eae99","permalink":"/project/scale-mids/","publishdate":"2022-04-01T00:00:00Z","relpermalink":"/project/scale-mids/","section":"project","summary":"In this project, we seek to address the following question: can weather and airline data collected two hours before the scheduled departure time, predict whether the flight will be delayed 15 minutes or more?","tags":["Machine Learning","Data Science","Statistics","MIDS"],"title":"Will Your Flights be Delayed?","type":"project"},{"authors":null,"categories":null,"content":"The effects of the COVID-19 pandemic have been felt and are still being felt around the world. In particular, the tourism industry suffered extreme economic losses between the many travel restrictions, cessation of communal social activities, and widespread fear of contracting the virus. Specifically, in 2020, there was a $35%$ reduction in domestic travel, resulting significant revenue loss. By contrast, there was an uptick in domestic travel in 2021. In this project, we seek to understand how vaccination rates are impacting vacation mobility in the Pacific Northwest during summer 2021. We explore the relationship between number of trips between 100 and 500 miles and COVID-19 vaccinations controlled for key related attributes, including population density and number of COVID-19 cases. In addition, we also consider several additional factors that influence travel, such as employment status, state restrictions, and political ideology. We also note that this study only focuses on a small time period -July 4th weekend.\n","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"86ca56d3952cf46ced7bb2c947aa38e2","permalink":"/project/stats-mids/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/project/stats-mids/","section":"project","summary":"In this project, we seek to understand how vaccination rates are impacting vacation mobility in the Pacific Northwest during summer 2021.","tags":["Statistics","MIDS"],"title":"What made the Pacific Northwest move during the July 4th weekend?","type":"project"},{"authors":null,"categories":null,"content":"Connectors bring in telemetry and analytics data from various vantage points in a data center. Typical connectors include network switches and routers, application delivery controllers such as F5 Big-IP and Citrix NetScaler, and firewalls. Tetration uses the data collected from such connectors to baseline the behavior in a network and automatically organize the workloads in the data center. In addition, Tetration also recommends Zero-Trust policies and enforces them. As part of this project, I designed and developed a framework for the lifecycle management of connector integration, including: (i) creation of the connector integration, (ii) configuration management of the connectors, and (iii) troubleshooting infrastructure.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"185aecb8ecf0474a4240605d2cfb787d","permalink":"/project/connectors-tetration/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/connectors-tetration/","section":"project","summary":"Connectors bring in telemetry andanalytics data from various vantage points in a data center.","tags":["Professional"],"title":"Lifecycle management of Tetration Connectors","type":"project"},{"authors":null,"categories":null,"content":"My website does not host third-party cookies and hosts three first-party cookies just to generally understand the audience of the website. The cookies are from Google Analytics.\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/privacy/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/privacy/","section":"","summary":"My website does not host third-party cookies and hosts three first-party cookies just to generally understand the audience of the website. The cookies are from Google Analytics.","tags":null,"title":"Privacy Policy","type":"page"},{"authors":null,"categories":null,"content":"StyleBooks is a declarative language that allow users to consume NetScaler (now, called Citrix ADC) services in a variety of data center configurations and cloud architectures, providing both configuration simplification and smart operational visibility. It captures useful NetScaler configuration and includes operational aspects (health, counters, logs). New StyleBooks can be created by cloning and modifying existing ones, or by composing existing StyleBooks into new ones, thus, allowing for modular and incremental design. In this project, I was responsible for the following: (i) compiler for StyleBooks that generates an equivalent Python package, (ii) design of the runtime engine that instantiates a compiled StyleBook to create an actual configuration, (iii) design of config audit and config diffs for computing the differences when an existing configuration is updated, (iv) design of the REST APIs.\n","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496275200,"objectID":"eb96768ed87d0be046240580846d198c","permalink":"/project/stylebooks-citrix/","publishdate":"2017-06-01T00:00:00Z","relpermalink":"/project/stylebooks-citrix/","section":"project","summary":"StyleBooks is a declarative language that allow users to consume NetScaler (now, called Citrix ADC) services in a variety of data center configurations and cloud architectures, providing both configuration simplification and smart operational visibility.","tags":["Professional"],"title":"StyleBooks: A declarative configuration language for Citrix ADC","type":"project"},{"authors":null,"categories":null,"content":"DHT provides a key-value store for NetScaler (now, called Citrix ADC) packet engines to store application state in multiple cores of a node or across multiple nodes/cores in a cluster. DHT provides eventual consistency semantics to the applications. In this project, I was responsible for the following: (i) reliable replication of entries across the nodes, (ii) dealing with nodes joining/leaving (transitional period) the cluster, (iii) hunting for existing key-value entry in the cluster during transitional period.\n","date":1417392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417392000,"objectID":"009343a14d87100b1a27cb3c23fa4359","permalink":"/project/dht-citrix/","publishdate":"2014-12-01T00:00:00Z","relpermalink":"/project/dht-citrix/","section":"project","summary":"DHT provides a key-value store for NetScaler (now, called Citrix ADC) packet engines to store application state in multiple cores of a node or across multiple nodes/cores in a cluster.","tags":["Professional"],"title":"Distributed hash table for Cluster of Citrix ADCs","type":"project"}]